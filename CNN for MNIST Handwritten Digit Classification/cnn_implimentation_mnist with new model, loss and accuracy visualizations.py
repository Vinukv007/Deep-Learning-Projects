# -*- coding: utf-8 -*-
"""cnn implimentation mnist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qKj8DnQyfBdpcxuIoQ1QVUep3MHRY8PZ
"""

import pandas as pd
from keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D,Flatten

mnist

help(mnist)

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train.shape

x_train[0].shape  #shape of each image

pd.DataFrame(x_train[0])

for i in range(5):
  plt.imshow(x_train[i])
  plt.show()

for i in range(3):
  plt.imshow(x_train[i],cmap='Greys_r')
  plt.show()

#normalising the pixels
x_train=x_train/255
x_test=x_test/255

#Since MNIST data is a gray scale dataset, so last channel is 1. if data had been RGB images last channel would have been 3.

x_train=x_train.reshape(x_train.shape[0],28,28,1)

x_test=x_test.reshape(x_test.shape[0],28,28,1)

np.unique(y_train)

# converting data to categorical values

from keras.utils import to_categorical
y_train=to_categorical(y_train)

y_train[0]

y_test=to_categorical(y_test)

model=Sequential()
model.add
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPool2D((2,2)))
model.add(Flatten())
model.add(Dense(64,activation='relu'))
model.add(Dense(10, activation='softmax'))

model.summary()

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

data=model.fit(x_train, y_train, batch_size=64, epochs=20,validation_data=(x_test, y_test), verbose=0)

loss, accuracy=model.evaluate(x_test, y_test)

accuracy

# plot loss
plt.subplot(211)
plt.title('Cross Entropy Loss')
plt.plot(data.history['loss'], color='blue', label='train')
plt.plot(data.history['val_loss'], color='orange', label='test')
# plot accuracy
plt.subplot(212)
plt.title('Classification Accuracy')
plt.plot(data.history['accuracy'], color='blue', label='train')
plt.plot(data.history['val_accuracy'], color='orange', label='test')

# Trying different model

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(28, 28, 1)))
model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(MaxPool2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
model.add(Dense(10, activation='softmax'))
 # compile model
opt = SGD(lr=0.001, momentum=0.9)
model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

data=model.fit(x_train, y_train, batch_size=64, epochs=20,validation_data=(x_test, y_test), verbose=0)

# plot loss
plt.subplot(211)
plt.title('Cross Entropy Loss')
plt.plot(data.history['loss'], color='blue', label='train')
plt.plot(data.history['val_loss'], color='orange', label='test')
# plot accuracy
plt.subplot(212)
plt.title('Classification Accuracy')
plt.plot(data.history['accuracy'], color='blue', label='train')
plt.plot(data.history['val_accuracy'], color='orange', label='test')

data.history['val_accuracy']

